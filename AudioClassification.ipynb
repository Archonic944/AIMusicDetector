{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install resampy\n",
    "!pip3 install librosa\n",
    "!pip3 install joblib\n",
    "!pip3 install tensorflow\n",
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgaOh7v01Duq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "LOAD_MODEL = True # Whether to train the model, or just evaluate based on 21Jan2025.h5\n",
    "\n",
    "AUDIO_CONTENT_DIR = 'content/audio'       # Original audio directory\n",
    "FEATURES_CONTENT_DIR = 'content/features' # Pre-calculated features (MFCCs)\n",
    "classes = [\"human\", \"ai\"]\n",
    "\n",
    "SEGMENT_DURATION = 1.0  # Duration of each audio segment in seconds\n",
    "HOP_LENGTH = 1.0        # Hop length in seconds between segments (should usually be the same as segment duration)\n",
    "PAD_LEN = 40           # Fixed length for MFCC padding/truncating\n",
    "MFCC_COUNT = 40        # Number of MFCCs per set (set this according to segment duration)\n",
    "\n",
    "# Volume is randomized during normalization between these two values\n",
    "MAX_TARGET_DB = -20 \n",
    "MIN_TARGET_DB = -40 \n",
    "\n",
    "# Utils\n",
    "def db_to_linear(db):\n",
    "    return 10 ** (db / 20)\n",
    "def linear_to_db(rms):\n",
    "    return 20 * np.log10(rms) if rms > 0 else -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BAbfUNl1KYf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the chop_audio Function\n",
    "def chop_audio(audio, sample_rate=22050, segment_duration=SEGMENT_DURATION, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Splits an audio array into multiple segments.\n",
    "\n",
    "    Parameters:\n",
    "    - audio (np.ndarray): The original audio signal.\n",
    "    - sample_rate (int): The sample rate of the audio.\n",
    "    - segment_duration (float): Duration of each segment in seconds.\n",
    "    - hop_duration (float): Time to skip between segments in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - List[np.ndarray]: List of audio segments.\n",
    "    \"\"\"\n",
    "    segment_length_samples = int(segment_duration * sample_rate)\n",
    "    hop_length_samples = int(hop_length * sample_rate)\n",
    "    segments = []\n",
    "\n",
    "    for start in range(0, len(audio) - segment_length_samples + 1, hop_length_samples):\n",
    "        end = start + segment_length_samples\n",
    "        segment = audio[start:end]\n",
    "        segments.append(segment)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI6QH0yP1LnV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(audio, sample_rate=22050, pad_len=PAD_LEN):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features from an audio segment and pads/truncates them to a fixed length.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio (np.ndarray): The audio segment.\n",
    "    - sample_rate (int): The sample rate of the audio.\n",
    "    - pad_len (int): The fixed length for padding/truncating.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: MFCC feature array of shape (40, PAD_LEN).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        \n",
    "        # Calculate padding or truncating\n",
    "        pad_width = pad_len - mfccs.shape[1]\n",
    "        \n",
    "        if pad_width > 0:\n",
    "            # Pad MFCCs with zeros on the right\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            # Truncate MFCCs to the desired length\n",
    "            mfccs = mfccs[:, :pad_len]\n",
    "        \n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature extraction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_loudness(audio, max_db=MAX_TARGET_DB, min_db=MIN_TARGET_DB, debug=False):\n",
    "    \"\"\"\n",
    "    Normalizes the loudness of an audio segment to a random target RMS between min_db and max_db,\n",
    "    ensuring that no clipping occurs. Logs the difference from the original dB if clipping is prevented.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio (np.ndarray): The audio segment.\n",
    "    - max_db (float): Maximum target RMS in decibels.\n",
    "    - min_db (float): Minimum target RMS in decibels.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: The normalized audio segment.\n",
    "    \"\"\"\n",
    "    target_db = random.uniform(min_db, max_db)\n",
    "    target_rms = db_to_linear(target_db)\n",
    "    \n",
    "    current_rms = np.sqrt(np.mean(audio**2))\n",
    "    if current_rms == 0:\n",
    "        return audio  # Avoid division by zero\n",
    "    \n",
    "    desired_scaling = target_rms / current_rms\n",
    "    max_sample = np.max(np.abs(audio * desired_scaling))\n",
    "    \n",
    "    if max_sample > 1.0:\n",
    "        # Calculate scaling factor to prevent clipping\n",
    "        clipping_scaling = 1.0 / np.max(np.abs(audio))\n",
    "        # Choose the smaller scaling factor\n",
    "        scaling_factor = min(desired_scaling, clipping_scaling)\n",
    "        adjusted_rms = current_rms * scaling_factor\n",
    "        adjusted_db = linear_to_db(adjusted_rms)\n",
    "        db_difference = adjusted_db - target_db\n",
    "        if debug:\n",
    "            print(f\"Clipping prevented: Original target_db={target_db:.2f} dB, \"\n",
    "              f\"Adjusted target_db={adjusted_db:.2f} dB, Difference={db_difference:.2f} dB\")\n",
    "    else:\n",
    "        scaling_factor = desired_scaling\n",
    "    \n",
    "    normalized_audio = audio * scaling_factor\n",
    "    return normalized_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_save_npy(file_path, label, output_dir, augment=True, force=False):\n",
    "    \"\"\"\n",
    "    Processes a single audio file: extracts MFCC features and saves them as a compressed .npz file.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the audio file.\n",
    "    - label (int): Label of the audio file (0 for human, 1 for ai).\n",
    "    - output_dir (str): Directory to save the .npz feature file.\n",
    "    - augment (bool): If True, apply loudness normalization. If False, skip normalization.\n",
    "    - force (bool): If True, overwrite existing feature files.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}.npz\")\n",
    "        \n",
    "        # Check if feature file is already saved. Does not perform additional checks like if the feature file matches the CURRENT segment length.\n",
    "        if os.path.exists(output_file) and not force:\n",
    "            print(f\"Features for '{base_name}' already exist. Skipping.\")\n",
    "            return\n",
    "        \n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast', mono=True)\n",
    "        \n",
    "        # Chop the audio into segments\n",
    "        segments = chop_audio(audio, sample_rate, SEGMENT_DURATION, HOP_LENGTH)\n",
    "        \n",
    "        # Extract features for each segment\n",
    "        features = []\n",
    "        for segment in segments:\n",
    "            if augment:\n",
    "                normalized_segment = normalize_loudness(segment, MAX_TARGET_DB, MIN_TARGET_DB)\n",
    "            else:\n",
    "                normalized_segment = segment  # Skip normalization for validation\n",
    "            mfcc = extract_features(normalized_segment, sample_rate, PAD_LEN)\n",
    "            if mfcc is not None:\n",
    "                features.append(mfcc.astype(np.float32))  # Ensure float32 for consistency\n",
    "        \n",
    "        if not features:\n",
    "            print(f\"No features extracted for '{base_name}'. Skipping saving.\")\n",
    "            return\n",
    "        \n",
    "        # Convert to numpy array and add channel dimension\n",
    "        features = np.array(features, dtype=np.float32)[..., np.newaxis]  # Shape: (num_segments, 40, PAD_LEN, 1)\n",
    "        \n",
    "        # Save as compressed .npz file\n",
    "        np.savez_compressed(output_file, features=features, label=label)\n",
    "        print(f\"Saved features for '{base_name}' to '{output_file}'\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing '{file_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FvQ8jFL1OqV",
    "outputId": "7ee81354-5cdc-4730-beee-294b27e23b64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_features(feature_dir, classes):\n",
    "    \"\"\"\n",
    "    Loads precomputed features from training and validation directories and maps them to file names.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_dir (str): Path to the features directory.\n",
    "    - classes (list): List of class names (e.g., [\"human\", \"ai\"]).\n",
    "    \n",
    "    Returns:\n",
    "    - features_mapping (dict): Dictionary mapping file names (without extension) to their features and labels.\n",
    "    \"\"\"\n",
    "    features_mapping = {}\n",
    "    splits = ['train', 'validation']\n",
    "    \n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            subdir_path = os.path.join(feature_dir, split, cls)\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                print(f\"Directory '{subdir_path}' does not exist. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            label = classes.index(cls)  # 0 for human, 1 for ai\n",
    "            \n",
    "            for file in os.listdir(subdir_path):\n",
    "                if file.lower().endswith('.npz'):\n",
    "                    base_name = os.path.splitext(file)[0]\n",
    "                    if base_name in features_mapping:\n",
    "                        print(f\"Features for '{base_name}' already loaded. Skipping.\")\n",
    "                        continue\n",
    "                    \n",
    "                    file_path = os.path.join(subdir_path, file)\n",
    "                    try:\n",
    "                        with np.load(file_path) as data:\n",
    "                            features = data['features']\n",
    "                            label = int(data['label'])\n",
    "                            features_mapping[base_name] = {\n",
    "                                'features': features,  # Shape: (num_segments, 40, PAD_LEN, 1)\n",
    "                                'label': label         # 0 for human, 1 for ai\n",
    "                            }\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading '{file_path}': {e}\")\n",
    "    \n",
    "    print(f\"Total feature files loaded: {len(features_mapping)}\")\n",
    "    return features_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_all_features(force=False):\n",
    "    \"\"\"\n",
    "    Processes and saves features from both training and validation directories.\n",
    "    \n",
    "    Parameters:\n",
    "    - force (bool): If True, overwrite existing feature files.\n",
    "    \n",
    "    Returns:\n",
    "    - train_files (list): List of training file names (without extension).\n",
    "    - val_files (list): List of validation file names (without extension).\n",
    "    \"\"\"\n",
    "    classes = [\"human\", \"ai\"]\n",
    "    \n",
    "    # Define splits; used to determine file paths\n",
    "    splits = {\n",
    "        'train': True,        # Apply augmentation\n",
    "        'validation': False   # Do not apply augmentation\n",
    "    }\n",
    "    \n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    \n",
    "    for split, augment in splits.items():\n",
    "        for cls in classes:\n",
    "            cls_audio_dir = os.path.join(AUDIO_CONTENT_DIR, split, cls)\n",
    "            cls_feature_dir = os.path.join(FEATURES_CONTENT_DIR, split, cls)\n",
    "            for f in os.listdir(cls_audio_dir):\n",
    "                if f.lower().endswith(('.wav', '.mp3')):\n",
    "                    file_path = os.path.join(cls_audio_dir, f)\n",
    "                    label = classes.index(cls)\n",
    "                    process_and_save_npy(file_path, label, cls_feature_dir, augment=augment, force=force)\n",
    "                    \n",
    "                    base_name = os.path.splitext(f)[0]\n",
    "                    if split == 'train':\n",
    "                        train_files.append(base_name)\n",
    "                    else:\n",
    "                        val_files.append(base_name)\n",
    "                    \n",
    "    print(\"Feature extraction and saving complete.\")\n",
    "    print(f\"Training files: {len(train_files)}\")\n",
    "    print(f\"Validation files: {len(val_files)}\")\n",
    "    \n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify_class_distribution(y, dataset_type='Dataset'):\n",
    "    class_labels = np.argmax(y, axis=1)\n",
    "    unique, counts = np.unique(class_labels, return_counts=True)\n",
    "    class_distribution = dict(zip(['human', 'ai'], counts))\n",
    "    print(f\"{dataset_type} class distribution: {class_distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify_directory_structure(feature_dir, audio_dir, classes=[\"human\", \"ai\"], splits=[\"train\", \"validation\"]):\n",
    "    \"\"\"\n",
    "    Verifies the directory structure and ensures that the number of feature files matches the number of audio files.\n",
    "    Prints details including the effective split percentages between train and validation for each class.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_dir (str): Path to the base features directory (e.g., 'content/features').\n",
    "    - audio_dir (str): Path to the base audio directory (e.g., 'content/audio').\n",
    "    - classes (list): List of class names (e.g., [\"human\", \"ai\"]).\n",
    "    - splits (list): List of data splits (e.g., [\"train\", \"validation\"]).\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(f\"Verifying directory structure between '{audio_dir}' and '{feature_dir}'...\\n\")\n",
    "    \n",
    "    counts = {cls: {split: {\"audio\": 0, \"features\": 0} for split in splits} for cls in classes}\n",
    "    total_counts = {cls: {\"audio\": 0, \"features\": 0} for cls in classes}\n",
    "    \n",
    "    # Flag to track overall structure validity\n",
    "    structure_valid = True\n",
    "    \n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            audio_split_dir = os.path.join(audio_dir, split, cls)\n",
    "            feature_split_dir = os.path.join(feature_dir, split, cls)\n",
    "            \n",
    "            # Check if directories exist\n",
    "            if not os.path.isdir(audio_split_dir):\n",
    "                print(f\"Missing audio directory: '{audio_split_dir}'\")\n",
    "                structure_valid = False\n",
    "            if not os.path.isdir(feature_split_dir):\n",
    "                print(f\"Missing feature directory: '{feature_split_dir}'\")\n",
    "                structure_valid = False\n",
    "                continue  # Skip counting if feature directory doesn't exist\n",
    "            \n",
    "            # Count audio files\n",
    "            audio_files = [f for f in os.listdir(audio_split_dir) if f.lower().endswith(('.wav', '.mp3'))]\n",
    "            audio_count = len(audio_files)\n",
    "            counts[cls][split][\"audio\"] = audio_count\n",
    "            total_counts[cls][\"audio\"] += audio_count\n",
    "            \n",
    "            # Count feature files\n",
    "            feature_files = [f for f in os.listdir(feature_split_dir) if f.lower().endswith('.npz')]\n",
    "            feature_count = len(feature_files)\n",
    "            counts[cls][split][\"features\"] = feature_count\n",
    "            total_counts[cls][\"features\"] += feature_count\n",
    "            \n",
    "            # Print counts\n",
    "            print(f\"Class '{cls}' - Split '{split}':\")\n",
    "            print(f\"  Audio files: {audio_count}\")\n",
    "            print(f\"  Feature files: {feature_count}\\n\")\n",
    "            \n",
    "            # Check if counts match\n",
    "            if audio_count != feature_count:\n",
    "                print(f\"Mismatch in counts for Class '{cls}', Split '{split}':\")\n",
    "                print(f\"  Audio files: {audio_count} vs Feature files: {feature_count}\\n\")\n",
    "                structure_valid = False\n",
    "    \n",
    "    if not structure_valid:\n",
    "        print(\"Directory structure verification failed due to missing directories or mismatched file counts.\\n\")\n",
    "    else:\n",
    "        print(\"All directories exist and file counts match.\\n\")\n",
    "    \n",
    "    print(\"Effective Split Percentages:\\n\")\n",
    "    for cls in classes:\n",
    "        train_audio = counts[cls][\"train\"][\"audio\"]\n",
    "        val_audio = counts[cls][\"validation\"][\"audio\"]\n",
    "        total_audio = total_counts[cls][\"audio\"]\n",
    "        \n",
    "        if total_audio == 0:\n",
    "            print(f\"Class '{cls}': No audio files found.\")\n",
    "            continue\n",
    "        \n",
    "        train_pct = (train_audio / total_audio) * 100\n",
    "        val_pct = (val_audio / total_audio) * 100\n",
    "        \n",
    "        print(f\"Class '{cls}':\")\n",
    "        print(f\"  Training: {train_audio} files ({train_pct:.2f}%)\")\n",
    "        print(f\"  Validation: {val_audio} files ({val_pct:.2f}%)\\n\")\n",
    "    \n",
    "    print(\"Verification Summary:\")\n",
    "    for cls in classes:\n",
    "        total_audio = total_counts[cls][\"audio\"]\n",
    "        total_features = total_counts[cls][\"features\"]\n",
    "        print(f\"Class '{cls}' - Total Audio Files: {total_audio}, Total Feature Files: {total_features}\")\n",
    "    print(\"\\nDirectory structure verification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_val(features_mapping, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the files into training and validation sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - features_mapping (dict): Dictionary mapping file names to their features and labels.\n",
    "    - val_size (float): Proportion of the dataset to include in the validation split.\n",
    "    - random_state (int): Seed used by the random number generator.\n",
    "    \n",
    "    Returns:\n",
    "    - train_files (list): List of file names for training.\n",
    "    - val_files (list): List of file names for validation.\n",
    "    \"\"\"\n",
    "    file_names = list(features_mapping.keys())\n",
    "    labels = [features_mapping[file]['label'] for file in file_names]\n",
    "    \n",
    "    train_files, val_files = train_test_split(\n",
    "        file_names,\n",
    "        test_size=val_size,\n",
    "        stratify=labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Training files: {len(train_files)}\")\n",
    "    print(f\"Validation files: {len(val_files)}\")\n",
    "    \n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def pool_features(feature_mapping, selected_files):\n",
    "    \"\"\"\n",
    "    Pools all features and labels from the selected files into single arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_mapping (dict): Dictionary mapping file names to their features and labels.\n",
    "    - selected_files (list): List of file names to include.\n",
    "    \n",
    "    Returns:\n",
    "    - X (np.ndarray): Pooled feature arrays.\n",
    "    - y (np.ndarray): Pooled labels.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for file_name in selected_files:\n",
    "        data = feature_mapping.get(file_name)\n",
    "        if data is None:\n",
    "            print(f\"No data found for '{file_name}'. Skipping.\")\n",
    "            continue\n",
    "        X.append(data['features'])  # Each element has shape (num_segments, 40, PAD_LEN, 1)\n",
    "        y.extend([data['label']] * data['features'].shape[0])  # Repeat label for each segment\n",
    "    \n",
    "    if X:\n",
    "        X = np.concatenate(X, axis=0)  # Shape: (total_segments, 40, PAD_LEN, 1)\n",
    "    else:\n",
    "        X = np.array([])\n",
    "    \n",
    "    y = np.array(y)  # Shape: (total_segments,)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def verify_directory_structure(feature_dir, classes=[\"human\", \"ai\"], splits=[\"train\", \"validation\"]):\n",
    "    \"\"\"\n",
    "    Verifies the directory structure and file counts for training and validation datasets.\n",
    "    Prints details including the effective split percentage between train and validation for each class.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_dir (str): Path to the base features directory (e.g., 'content/features').\n",
    "    - classes (list): List of class names (e.g., [\"human\", \"ai\"]).\n",
    "    - splits (list): List of data splits (e.g., [\"train\", \"validation\"]).\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(f\"Verifying directory structure in '{feature_dir}'...\\n\")\n",
    "    \n",
    "    # Initialize dictionaries to hold counts\n",
    "    counts = {cls: {split: 0 for split in splits} for cls in classes}\n",
    "    total_counts = {cls: 0 for cls in classes}\n",
    "    \n",
    "    # Flag to track overall structure validity\n",
    "    structure_valid = True\n",
    "    \n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            split_cls_dir = os.path.join(feature_dir, split, cls)\n",
    "            \n",
    "            if not os.path.isdir(split_cls_dir):\n",
    "                print(f\"Missing directory: '{split_cls_dir}'\")\n",
    "                structure_valid = False\n",
    "                continue  # Skip counting if directory doesn't exist\n",
    "            \n",
    "            # List all .npz files in the directory\n",
    "            npz_files = [f for f in os.listdir(split_cls_dir) if f.lower().endswith('.npz')]\n",
    "            file_count = len(npz_files)\n",
    "            counts[cls][split] = file_count\n",
    "            total_counts[cls] += file_count\n",
    "            \n",
    "            print(f\"Directory: '{split_cls_dir}'\")\n",
    "            print(f\"  Number of .npz files: {file_count}\\n\")\n",
    "    \n",
    "    if not structure_valid:\n",
    "        print(\"Directory structure verification failed due to missing directories.\\n\")\n",
    "    else:\n",
    "        print(\"All required directories are present.\\n\")\n",
    "    \n",
    "    print(\"Effective Split Percentages:\\n\")\n",
    "    for cls in classes:\n",
    "        train_count = counts[cls][\"train\"]\n",
    "        val_count = counts[cls][\"validation\"]\n",
    "        total = total_counts[cls]\n",
    "        \n",
    "        if total == 0:\n",
    "            print(f\"Class '{cls}': No files found.\")\n",
    "            continue\n",
    "        \n",
    "        train_pct = (train_count / total) * 100\n",
    "        val_pct = (val_count / total) * 100\n",
    "        \n",
    "        print(f\"Class '{cls}':\")\n",
    "        print(f\"  Training: {train_count} files ({train_pct:.2f}%)\")\n",
    "        print(f\"  Validation: {val_count} files ({val_pct:.2f}%)\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"Verification Summary:\")\n",
    "    for cls in classes:\n",
    "        total = total_counts[cls]\n",
    "        print(f\"Class '{cls}' - Total Files: {total}\")\n",
    "    print(\"\\nDirectory structure verification complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save precomputed features; skip over ones that already exist. Set force to True after changing segment length or other parameters.\n",
    "train_files, val_files = save_all_features(force=False)\n",
    "\n",
    "verify_directory_structure(\"content/features\", \"content/audio\")\n",
    "\n",
    "# === Load Precomputed Features ===\n",
    "features_mapping = load_features(FEATURES_CONTENT_DIR, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "OVP_Z-1w2xWV",
    "outputId": "42ee3457-d933-4497-d69b-489d204527da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Features_mapping contains all files, so we must group them into validation and training\n",
    "\n",
    "X_train, y_train = pool_features(features_mapping, train_files)\n",
    "y_train_categorical = to_categorical(y_train, num_classes=2)\n",
    "print(f\"Pooled Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Pooled Training Labels Shape: {y_train_categorical.shape}\")\n",
    "\n",
    "X_val, y_val = pool_features(features_mapping, val_files)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=2)\n",
    "print(f\"Pooled Validation Features Shape: {X_val.shape}\")\n",
    "print(f\"Pooled Validation Labels Shape: {y_val_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not LOAD_MODEL:\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(40, PAD_LEN, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.7),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "else:\n",
    "    model = load_model(\"saved_models/21Jan2025.h5\")\n"
   ],
   "metadata": {
    "id": "dL9eDuUD2oKM",
    "tags": []
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not LOAD_MODEL: # Don't train the model if we are loading it\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train_categorical,\n",
    "        epochs=25,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val_categorical),\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_file(file_name, model, features_mapping, pad_len=PAD_LEN, debug=False):\n",
    "    \"\"\"\n",
    "    Evaluates a single file and computes the AI certainty percentage.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_name (str): Name of the file (without directory and extension).\n",
    "    - model (keras.Model): Trained Keras model for prediction.\n",
    "    - features_mapping (dict): Mapping of file names to their features and labels.\n",
    "    - pad_len (int): Fixed length for padding/truncating MFCCs.\n",
    "    - debug (bool): If True, prints debug information for each file processed.\n",
    "    \n",
    "    Returns:\n",
    "    - certainty (float): AI certainty percentage for the file.\n",
    "    \"\"\"\n",
    "    data = features_mapping.get(file_name)\n",
    "    if data is None:\n",
    "        found = False\n",
    "        for cls in classes:\n",
    "            audio_dir = os.path.join(AUDIO_CONTENT_DIR, cls)\n",
    "            audio_path_wav = os.path.join(audio_dir, f\"{file_name}.wav\")\n",
    "            audio_path_mp3 = os.path.join(audio_dir, f\"{file_name}.mp3\")\n",
    "            \n",
    "            if os.path.exists(audio_path_wav):\n",
    "                audio_path = audio_path_wav\n",
    "                label = classes.index(cls)\n",
    "                found = True\n",
    "                break\n",
    "            elif os.path.exists(audio_path_mp3):\n",
    "                audio_path = audio_path_mp3\n",
    "                label = classes.index(cls)\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"Audio file for '{file_name}' not found in any class directories.\")\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            audio, sample_rate = librosa.load(audio_path, res_type='kaiser_fast', mono=True)\n",
    "            segments = chop_audio(audio, sample_rate, SEGMENT_DURATION, HOP_LENGTH)\n",
    "            \n",
    "            features = []\n",
    "            for segment in segments:\n",
    "                # Do not apply loudness normalization for validation\n",
    "                mfcc = extract_features(segment, sample_rate, pad_len)\n",
    "                if mfcc is not None:\n",
    "                    features.append(mfcc.astype(np.float32)[..., np.newaxis])  # Shape: (40, PAD_LEN, 1)\n",
    "            \n",
    "            if not features:\n",
    "                print(f\"No features extracted for '{file_name}'.\")\n",
    "                return 0.0\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            features = np.array(features, dtype=np.float32)  # Shape: (num_segments, 40, PAD_LEN, 1)\n",
    "            \n",
    "            predictions = model.predict(features, batch_size=32, verbose=0)\n",
    "            predicted_classes = np.argmax(predictions, axis=1)  # Shape: (num_segments,)\n",
    "            \n",
    "            ai_segments = np.sum(predicted_classes == 1)\n",
    "            total_segments = len(predicted_classes)\n",
    "            certainty = (ai_segments / total_segments) * 100 if total_segments > 0 else 0\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"File: {file_name}, Class: {classes[label]}, AI Certainty: {certainty:.2f}%\")\n",
    "            \n",
    "            return certainty\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{file_name}': {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    else:\n",
    "        features = data['features']  # Shape: (num_segments, 40, PAD_LEN, 1)\n",
    "        label = data['label']        # 0 for Human, 1 for AI\n",
    "        \n",
    "        try:\n",
    "            # Predict classes for all segments in the file\n",
    "            predictions = model.predict(features, batch_size=32, verbose=0)\n",
    "            predicted_classes = np.argmax(predictions, axis=1)  # Shape: (num_segments,)\n",
    "            \n",
    "            # Calculate AI certainty\n",
    "            ai_segments = np.sum(predicted_classes == 1)\n",
    "            total_segments = len(predicted_classes)\n",
    "            certainty = (ai_segments / total_segments) * 100 if total_segments > 0 else 0\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"File: {file_name}, Class: {classes[label]}, AI Certainty: {certainty:.2f}%\")\n",
    "            \n",
    "            return certainty\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating file '{file_name}': {e}\")\n",
    "            return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not LOAD_MODEL:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_validation_files(model, val_files, features_mapping, pad_len=PAD_LEN, debug=False):\n",
    "    \"\"\"\n",
    "    Evaluates all files in the validation set and computes the distribution of AI certainty.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (keras.Model): Trained Keras model for prediction.\n",
    "    - val_files (list): List of validation file names (without directory and extension).\n",
    "    - features_mapping (dict): Mapping of file names to their features and labels.\n",
    "    - pad_len (int): Fixed length for padding/truncating MFCCs.\n",
    "    - debug (bool): If True, prints debug information for each file processed.\n",
    "    \n",
    "    Returns:\n",
    "    - human_file_results (list): AI certainty percentages for Human files.\n",
    "    - ai_file_results (list): AI certainty percentages for AI files.\n",
    "    \"\"\"\n",
    "    human_file_results = []\n",
    "    ai_file_results = []\n",
    "    \n",
    "    for file_name in val_files:\n",
    "        certainty = evaluate_file(file_name, model, features_mapping, pad_len=pad_len, debug=debug)\n",
    "        \n",
    "        label = features_mapping[file_name]['label'] if file_name in features_mapping else None\n",
    "        if label == 0:\n",
    "            human_file_results.append(certainty)\n",
    "        elif label == 1:\n",
    "            ai_file_results.append(certainty)\n",
    "        \n",
    "        file_type = 'Human' if label == 0 else 'AI' if label == 1 else 'Unknown'\n",
    "        print(f\"Processed File: {file_name}, Label: {file_type}, AI Certainty: {certainty:.2f}%\")\n",
    "    \n",
    "    # Compute Averages\n",
    "    average_human_certainty = np.mean(human_file_results) if human_file_results else 0\n",
    "    average_ai_certainty = np.mean(ai_file_results) if ai_file_results else 0\n",
    "    \n",
    "    # Print Results\n",
    "    print(\"\\n----- Evaluation Results -----\")\n",
    "    print(f\"Average AI Certainty for Human Files: {average_human_certainty:.2f}%\")\n",
    "    print(f\"Average AI Certainty for AI Files: {average_ai_certainty:.2f}%\")\n",
    "    \n",
    "    return human_file_results, ai_file_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_results, ai_results = evaluate_validation_files(\n",
    "    model, \n",
    "    val_files, \n",
    "    features_mapping, \n",
    "    pad_len=PAD_LEN, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on validation data\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_val, y_val_categorical, batch_size=32, verbose=1)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels = ['Human'] * len(human_results) + ['AI'] * len(ai_results)\n",
    "certainties = human_results + ai_results\n",
    "\n",
    "base_x = {'Human': 0.4, 'AI': 0.6}\n",
    "x_values = [base_x[label] for label in labels]\n",
    "\n",
    "jitter_strength = 0.01\n",
    "x_values_jittered = [x + np.random.uniform(-jitter_strength, jitter_strength) for x in x_values]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    x_values_jittered, \n",
    "    certainties, \n",
    "    color='green', \n",
    "    alpha=0.4,         \n",
    "    edgecolors='none', \n",
    "    s=80               \n",
    ")\n",
    "\n",
    "plt.xticks([0.4, 0.6], ['Human', 'AI'], fontsize=18)\n",
    "\n",
    "plt.xlabel('Label', fontsize=16)\n",
    "plt.ylabel('AI Certainty (%)', fontsize=16)\n",
    "plt.title('Distribution of AI Certainty for Human and AI Music Files (Validation)', fontsize=18)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlim(0.2, 0.8)\n",
    "\n",
    "# Move the annotation to the right side, just outside the plot\n",
    "plt.text(0.82, 50, '1 dot = 1 song', rotation=90, fontsize=14, va='center', ha='left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "human_df = pd.DataFrame({\n",
    "    'file_type': ['human'] * len(human_results),\n",
    "    'ai_certainty_percentage': human_results\n",
    "})\n",
    "\n",
    "ai_df = pd.DataFrame({\n",
    "    'file_type': ['ai'] * len(ai_results),\n",
    "    'ai_certainty_percentage': ai_results\n",
    "})\n",
    "\n",
    "combined_df = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "\n",
    "from datetime import date\n",
    "combined_df.to_csv(str(date.today()) + \"_\" + date.today().strftime(\"%b-%d-%Y\") + '_data.csv', index=False)\n",
    "\n",
    "print(\"Results have been saved\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_segment_bars(segments, predicted_classes, file_name, confidence, gap=0.01):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    n = len(segments)\n",
    "    if n == 0:\n",
    "        print(\"No segments to plot.\")\n",
    "        return\n",
    "\n",
    "    random_heights = np.random.uniform(20, 50, n)\n",
    "    total_width = 1.0\n",
    "    bar_width = (total_width - (n + 1) * gap) / n\n",
    "    x_positions = [gap + i*(bar_width + gap) + bar_width/2 for i in range(n)]\n",
    "\n",
    "    colors = ['red' if p == 1 else 'gray' for p in predicted_classes]\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for x, height, color in zip(x_positions, random_heights, colors):\n",
    "        plt.bar(x, height, width=bar_width/(n/10), color=color, bottom=-height/2, align='center')\n",
    "\n",
    "    xticks = x_positions\n",
    "    times = [i * HOP_LENGTH for i in range(n)]\n",
    "    \n",
    "    time_labels = [f\"{int(t//60):02}:{int(t%60):02}\" for t in times]\n",
    "    filtered_xticks = [xticks[i] for i in range(n) if times[i] % 20 == 0]\n",
    "    filtered_time_labels = [time_labels[i] for i in range(n) if times[i] % 20 == 0]\n",
    "    \n",
    "    plt.xticks(filtered_xticks, filtered_time_labels, rotation=45)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (mm:ss)\")\n",
    "    plt.title(file_name + \" | AI Certainty: \" + f\"{confidence:.2f}%\")\n",
    "    \n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='gray', lw=5, label='Human'),\n",
    "        Line2D([0], [0], color='red', lw=5, label='AI')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    \n",
    "    plt.xlim(0, total_width)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T22:29:59.560722Z",
     "start_time": "2025-02-16T22:29:59.547001Z"
    }
   },
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-17T00:02:46.339808Z",
     "start_time": "2025-02-17T00:02:46.328787Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_independent_file(file_path, model, classes=classes, \n",
    "                              SEGMENT_DURATION=SEGMENT_DURATION, HOP_LENGTH=HOP_LENGTH, \n",
    "                              PAD_LEN=PAD_LEN, debug=False, image_gen=True):\n",
    "    \"\"\"\n",
    "    Evaluates an independent audio file by converting it to mono 64kbps mp3, extracting MFCC features \n",
    "    (without normalization), computing the AI certainty percentage using the provided model, and (if image_gen=True) \n",
    "    calling plot_segment_bars to visualize the segments.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the input audio file.\n",
    "    - model (keras.Model): Trained Keras model for prediction.\n",
    "    - classes (list): List of class names (e.g., [\"human\", \"ai\"]).\n",
    "    - SEGMENT_DURATION (float): Duration of each audio segment in seconds.\n",
    "    - HOP_LENGTH (float): Hop length in seconds between segments.\n",
    "    - PAD_LEN (int): Fixed length for MFCC padding/truncating.\n",
    "    - debug (bool): If True, prints debug information.\n",
    "    - image_gen (bool): If True, calls plot_segment_bars to display the visualization.\n",
    "    \n",
    "    Returns:\n",
    "    - certainty (float): AI certainty percentage for the file.\n",
    "    \"\"\"\n",
    "    import tempfile, subprocess, os, numpy as np, librosa\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary file for the converted mp3\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            temp_mp3_path = tmp.name\n",
    "        \n",
    "        # Convert to mono 64kbps mp3 using ffmpeg\n",
    "        ffmpeg_command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", file_path,\n",
    "            \"-ar\", \"22050\",      # Sample rate\n",
    "            \"-ac\", \"1\",          # Mono\n",
    "            \"-b:a\", \"64k\",       # Bitrate\n",
    "            \"-y\",                # Overwrite if exists\n",
    "            temp_mp3_path\n",
    "        ]\n",
    "        subprocess.run(ffmpeg_command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "        \n",
    "        audio, sample_rate = librosa.load(temp_mp3_path, sr=22050, mono=True)\n",
    "        \n",
    "        num_samples_per_segment = int(SEGMENT_DURATION * sample_rate)\n",
    "        hop_length_samples = int(HOP_LENGTH * sample_rate)\n",
    "        segments = []\n",
    "        for start in range(0, len(audio) - num_samples_per_segment + 1, hop_length_samples):\n",
    "            end = start + num_samples_per_segment\n",
    "            segments.append(audio[start:end])\n",
    "        \n",
    "        # Extract features for each segment without normalization\n",
    "        features = []\n",
    "        for segment in segments:\n",
    "            mfcc = extract_features(segment, sample_rate, PAD_LEN)\n",
    "            if mfcc is not None:\n",
    "                features.append(mfcc.astype(np.float32)[..., np.newaxis])\n",
    "        \n",
    "        if not features:\n",
    "            print(f\"No features extracted for '{file_path}'.\")\n",
    "            return 0.0\n",
    "        \n",
    "        features = np.array(features, dtype=np.float32)\n",
    "        \n",
    "        predictions = model.predict(features, batch_size=32, verbose=0)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Calculate AI certainty\n",
    "        ai_segments = np.sum(predicted_classes == 1)\n",
    "        total_segments = len(predicted_classes)\n",
    "        certainty = (ai_segments / total_segments) * 100 if total_segments > 0 else 0\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"File: {file_path}, AI Certainty: {certainty:.1f}%\")\n",
    "        \n",
    "        # Generate the visualization using plot_segment_bars if image_gen is True\n",
    "        if image_gen:\n",
    "            plot_segment_bars(segments, predicted_classes, os.path.splitext(os.path.basename(file_path))[0], certainty, gap=0.05)\n",
    "        \n",
    "        return certainty\n",
    "    \n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Error: ffmpeg failed to convert '{file_path}'.\")\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing '{file_path}': {e}\")\n",
    "        return 0.0\n",
    "    finally:\n",
    "        if os.path.exists(temp_mp3_path):\n",
    "            os.remove(temp_mp3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: content/audio/validation/ai/urgent-castle-escape.mp3, AI Certainty: 86.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "np.float64(86.76470588235294)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_independent_file(\"content/audio/validation/ai/urgent-castle-escape.mp3\", model, debug=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T22:30:31.523701Z",
     "start_time": "2025-02-16T22:30:30.673661Z"
    }
   },
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evaluate_independent_file(\"content/misc/youtube_sample.mp3\", model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
